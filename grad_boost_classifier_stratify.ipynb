{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier Model - with Stratification\n",
    "---\n",
    "The model in this notebook was strongly influenced by Natural Chan.  The following gradient boosted classifier will be used in an ordinal regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score\n",
    "\n",
    "import time\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kappa_score import qwkappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'ID' feature is already dropped from cleaning notebook\n",
    "\n",
    "# Open all source files as a pd dataframe\n",
    "# This dataset will be used to train the gradient boosted model\n",
    "orig_train = pd.read_csv('https://project4-wine-quality-2023.s3.us-west-2.amazonaws.com/train.csv')\n",
    "\n",
    "#This dataset will be used to evaluate again the Kaggle compitition entry submission\n",
    "orig_test = pd.read_csv('https://project4-wine-quality-2023.s3.us-west-2.amazonaws.com/test.csv')\n",
    "\n",
    "# Addition datasets to explore the GradBoost model on actual wine data\n",
    "red_data = pd.read_csv('https://raw.githubusercontent.com/Nicholas-Simpson/Project-4/main/Michael/red_white_data_noID.csv')\n",
    "white_data = pd.read_csv('https://raw.githubusercontent.com/Nicholas-Simpson/Project-4/main/Michael/white_data_noID.csv')\n",
    "red_white_data = pd.read_csv('https://raw.githubusercontent.com/Nicholas-Simpson/Project-4/main/Michael/red_white_data_noID.csv')\n",
    "trainable_data = pd.read_csv('https://raw.githubusercontent.com/Nicholas-Simpson/Project-4/main/Michael/trainable_data_noID.csv')\n",
    "\n",
    "# Drop 'ID' columns\n",
    "orig_test = orig_test.drop(columns='Id')\n",
    "orig_train = orig_train.drop(columns='Id')\n",
    "\n",
    "# Create a place to save any generated files\n",
    "gb_output_path = os.path.join(os.getcwd(),'grad boost output')\n",
    "os.makedirs(gb_output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train = orig_train.drop('quality', axis=1)\n",
    "y_train = orig_train['quality'].copy()\n",
    "X_test = orig_test.copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size = 0.2, \n",
    "                                                  random_state = 42) #because it is the answer :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Gradient Boosted Model Parameters\n",
    "Using the parameters from the best model search, investigate stratify and AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Regressor\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], # number of weak learning trees\n",
    "    'learning_rate': [0.01, 0.1, 0.2], # control possibility of overfitting.\n",
    "    # Strong interaction with n_estimators: smaller learning rates require more n_estimators\n",
    "    'max_depth': [3, 5, 7] #  size of each tree\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation, mark timer start\n",
    "start_time = time.time()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=skfold, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_gb = grid_search.best_estimator_\n",
    "grid_search_time = time.time()\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_gb.predict(X_val)\n",
    "\n",
    "# Report how long it took to complete Grid search and prediction\n",
    "end_time = time.time()\n",
    "grid_time = grid_search_time - start_time\n",
    "pred_time = end_time - grid_search_time\n",
    "tot_time = end_time - start_time\n",
    "\n",
    "print(f\"Time to complete Grid Search: {grid_time:.6f} seconds\")\n",
    "print(f\"Time to complete prediction: {pred_time:.6f} seconds\")\n",
    "print(f\"Total time to complete Grid Search and prediction: {tot_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "# the following metrics need to include the average type since the validation is ordinal and not binary\n",
    "f1 = f1_score(y_val, y_pred, average= 'weighted')\n",
    "precision = precision_score(y_val, y_pred, average= 'weighted')\n",
    "recall = recall_score(y_val, y_pred, average= 'weighted')\n",
    "kappa = cohen_kappa_score(y_val, y_pred, weights='quadratic')\n",
    "\n",
    "print(f\"First model scores:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Best Estimators: {best_gb.n_estimators}\")\n",
    "print(f\"Best Learning Rate: {best_gb.learning_rate}\")\n",
    "print(f\"Best Max Depth: {best_gb.max_depth}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Cohen Kappa Score, quadratic weighted: {kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of weak learner trees\n",
    "# Create a Gradient Boosting Regressor\n",
    "model_2 = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid_2 = {\n",
    "    'n_estimators': [200, 400, 800],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "start_time_2 = time.time()\n",
    "grid_search_2 = GridSearchCV(model_2, param_grid_2, cv=skfold, verbose=3)\n",
    "grid_search_2.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_gb_2 = grid_search_2.best_estimator_\n",
    "grid_search_time_2 = time.time()\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_2 = best_gb_2.predict(X_val)\n",
    "\n",
    "# Report how long it took to complete Grid search and prediction\n",
    "end_time_2 = time.time()\n",
    "grid_time_2 = grid_search_time_2 - start_time_2\n",
    "pred_time_2 = end_time_2 - grid_search_time_2\n",
    "tot_time_2 = end_time_2 - start_time_2\n",
    "\n",
    "print(f\"Time to complete Grid Search: {grid_time_2:.6f} seconds\")\n",
    "print(f\"Time to complete prediction: {pred_time_2:.6f} seconds\")\n",
    "print(f\"Total time to complete Grid Search and prediction: {tot_time_2:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_2 = accuracy_score(y_val, y_pred_2)\n",
    "# the following metrics need to include the average type since the validation is ordinal and not binary\n",
    "f1_2 = f1_score(y_val, y_pred_2, average= 'weighted')\n",
    "precision_2 = precision_score(y_val, y_pred_2, average= 'weighted')\n",
    "recall_2 = recall_score(y_val, y_pred_2, average= 'weighted')\n",
    "kappa_2 = cohen_kappa_score(y_val, y_pred_2, weights='quadratic')\n",
    "\n",
    "print(f\"Second model scores:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Best Estimators: {best_gb_2.n_estimators}\")\n",
    "print(f\"Best Learning Rate: {best_gb_2.learning_rate}\")\n",
    "print(f\"Best Max Depth: {best_gb_2.max_depth}\")\n",
    "print(f\"Accuracy: {accuracy_2:.2f}\")\n",
    "print(f\"F1: {f1_2:.2f}\")\n",
    "print(f\"Precision: {precision_2:.2f}\")\n",
    "print(f\"Recall: {recall_2:.2f}\")\n",
    "print(f\"Cohen Kappa Score, quadratic weighted: {kappa_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of weak learner trees\n",
    "# Create a Gradient Boosting Regressor\n",
    "model_3 = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid_3 = {\n",
    "    'n_estimators': [200, 400, 800],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "start_time_3 = time.time()\n",
    "grid_search_3 = GridSearchCV(model_3, param_grid_3, cv=skfold, verbose=3)\n",
    "grid_search_3.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_gb_3 = grid_search_3.best_estimator_\n",
    "grid_search_time_3 = time.time()\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_3 = best_gb_3.predict(X_val)\n",
    "\n",
    "# Report how long it took to complete Grid search and prediction\n",
    "end_time_3 = time.time()\n",
    "grid_time_3 = grid_search_time_3 - start_time_3\n",
    "pred_time_3 = end_time_3 - grid_search_time_3\n",
    "tot_time_3 = end_time_3 - start_time_3\n",
    "\n",
    "print(f\"Time to complete Grid Search: {grid_time_3:.6f} seconds\")\n",
    "print(f\"Time to complete prediction: {pred_time_3:.6f} seconds\")\n",
    "print(f\"Total time to complete Grid Search and prediction: {tot_time_3:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_3 = accuracy_score(y_val, y_pred_3)\n",
    "# the following metrics need to include the average type since the validation is ordinal and not binary\n",
    "f1_3 = f1_score(y_val, y_pred_3, average= 'weighted')\n",
    "precision_3 = precision_score(y_val, y_pred_3, average= 'weighted')\n",
    "recall_3 = recall_score(y_val, y_pred_3, average= 'weighted')\n",
    "kappa_3 = cohen_kappa_score(y_val, y_pred_3, weights='quadratic')\n",
    "\n",
    "print(f\"Third model scores:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Best Estimators: {best_gb_3.n_estimators}\")\n",
    "print(f\"Best Learning Rate: {best_gb_3.learning_rate}\")\n",
    "print(f\"Best Max Depth: {best_gb_3.max_depth}\")\n",
    "print(f\"Accuracy: {accuracy_3:.2f}\")\n",
    "print(f\"F1: {f1_3:.2f}\")\n",
    "print(f\"Precision: {precision_3:.2f}\")\n",
    "print(f\"Recall: {recall_3:.2f}\")\n",
    "print(f\"Cohen Kappa Score, quadratic weighted: {kappa_3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of weak learner trees\n",
    "# Create a Gradient Boosting Regressor\n",
    "model_4 = GradientBoostingClassifier()\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid_4 = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50, 75, 100, 150],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [2, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "start_time_4 = time.time()\n",
    "grid_search_4 = GridSearchCV(model_4, param_grid_4, cv=skfold, verbose=3)\n",
    "grid_search_4.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_gb_4 = grid_search_4.best_estimator_\n",
    "grid_search_time_4 = time.time()\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_4 = best_gb_4.predict(X_val)\n",
    "\n",
    "# Report how long it took to complete Grid search and prediction\n",
    "end_time_4 = time.time()\n",
    "grid_time_4 = grid_search_time_4 - start_time_4\n",
    "pred_time_4 = end_time_4 - grid_search_time_4\n",
    "tot_time_4 = end_time_4 - start_time_4\n",
    "\n",
    "print(f\"Time to complete Grid Search: {grid_time_4:.6f} seconds\")\n",
    "print(f\"Time to complete prediction: {pred_time_4:.6f} seconds\")\n",
    "print(f\"Total time to complete Grid Search and prediction: {tot_time_4:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_4 = accuracy_score(y_val, y_pred_4)\n",
    "# the following metrics need to include the average type since the validation is ordinal and not binary\n",
    "f1_4 = f1_score(y_val, y_pred_4, average= 'weighted')\n",
    "precision_4 = precision_score(y_val, y_pred_4, average= 'weighted')\n",
    "recall_4 = recall_score(y_val, y_pred_4, average= 'weighted')\n",
    "kappa_4 = cohen_kappa_score(y_val, y_pred_4, weights='quadratic')\n",
    "\n",
    "print(f\"Third model scores:\")\n",
    "print(\"-------------------\")\n",
    "print(f\"Best Estimators: {best_gb_4.n_estimators}\")\n",
    "print(f\"Best Learning Rate: {best_gb_4.learning_rate}\")\n",
    "print(f\"Best Max Depth: {best_gb_4.max_depth}\")\n",
    "print(f\"Accuracy: {accuracy_4:.2f}\")\n",
    "print(f\"F1: {f1_4:.2f}\")\n",
    "print(f\"Precision: {precision_4:.2f}\")\n",
    "print(f\"Recall: {recall_4:.2f}\")\n",
    "print(f\"Cohen Kappa Score, quadratic weighted: {kappa_4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Best Hyperparameters From the Second Round Grad Boost Model Search \n",
      "     Learning Rate =   0.01\n",
      "     Number of Trees = 400\n",
      "     Max Tree Depth =  2\n",
      "\n",
      "--------------------------------------------------------\n",
      "Second Round Grad Boosted Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.67      0.73      0.70       169\n",
      "           6       0.54      0.65      0.59       158\n",
      "           7       0.70      0.38      0.49        69\n",
      "           8       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.61       412\n",
      "   macro avg       0.32      0.29      0.30       412\n",
      "weighted avg       0.60      0.61      0.59       412\n",
      "\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Second Round Grad Boosted Quadratic Weighted Kappa Score: 0.4962\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(f\"Best Hyperparameters From the First Round Grad Boost Model Search \")\n",
    "print(f\"     Learning Rate =   {best_gb.learning_rate}\")\n",
    "print(f\"     Number of Trees = {best_gb.n_estimators}\")\n",
    "print(f\"     Max Tree Depth =  {best_gb.max_depth}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"First Round Grad Boosted Model Classification Report\")\n",
    "print(classification_report(y_val,y_pred))\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print()\n",
    "print(f\"First Round Grad Boosted Quadratic Weighted Kappa Score: {kappa:.4f}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(f\"Best Hyperparameters From the Second Round Grad Boost Model Search \")\n",
    "print(f\"     Learning Rate =   {best_gb_2.learning_rate}\")\n",
    "print(f\"     Number of Trees = {best_gb_2.n_estimators}\")\n",
    "print(f\"     Max Tree Depth =  {best_gb_2.max_depth}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Second Round Grad Boosted Model Classification Report\")\n",
    "print(classification_report(y_val,y_pred_2))\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print()\n",
    "print(f\"Second Round Grad Boosted Quadratic Weighted Kappa Score: {kappa_2:.4f}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(f\"Best Hyperparameters From the Third Round Grad Boost Model Search \")\n",
    "print(f\"     Learning Rate =   {best_gb_3.learning_rate}\")\n",
    "print(f\"     Number of Trees = {best_gb_3.n_estimators}\")\n",
    "print(f\"     Max Tree Depth =  {best_gb_3.max_depth}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Third Round Grad Boosted Model Classification Report\")\n",
    "print(classification_report(y_val,y_pred_3))\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print()\n",
    "print(f\"Third Round Grad Boosted Quadratic Weighted Kappa Score: {kappa_3:.4f}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(f\"Best Hyperparameters From the Fourth Round Grad Boost Model Search \")\n",
    "print(f\"     Learning Rate =   {best_gb_4.learning_rate}\")\n",
    "print(f\"     Number of Trees = {best_gb_4.n_estimators}\")\n",
    "print(f\"     Max Tree Depth =  {best_gb_4.max_depth}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Fourth Round Grad Boosted Model Classification Report\")\n",
    "print(classification_report(y_val,y_pred_4))\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print()\n",
    "print(f\"Forth Round Grad Boosted Quadratic Weighted Kappa Score: {kappa_4:.4f}\")\n",
    "print()\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m grid_spec \u001b[39m=\u001b[39m GridSpec(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, figure\u001b[39m=\u001b[39mfig, width_ratios \u001b[39m=\u001b[39m [\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m], height_ratios\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[39m# Model specs subplot\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model_specs \u001b[39m=\u001b[39m  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLearning Rate: \u001b[39m\u001b[39m{\u001b[39;00mbest_hp_3\u001b[39m.\u001b[39mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m, Tree Depth: \u001b[39m\u001b[39m{\u001b[39;00mbest_hp_3\u001b[39m.\u001b[39mmax_depth\u001b[39m}\u001b[39;00m\u001b[39m, Number of Trees: \u001b[39m\u001b[39m{\u001b[39;00mbest_hp_3\u001b[39m.\u001b[39mn_estimators\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mQuadratic Kappa Score: \u001b[39m\u001b[39m{\u001b[39;00mkappa_3\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m   \n\u001b[1;32m      7\u001b[0m upper_ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(grid_spec[\u001b[39m0\u001b[39m, :])\n\u001b[1;32m      9\u001b[0m \u001b[39m# plt.upper_ax_adjust(hspace = 0.5)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'learning_rate'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the figure and gridspec\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "grid_spec = GridSpec(2, 2, figure=fig, width_ratios = [3,3], height_ratios=[1, 6])\n",
    "\n",
    "# Model specs subplot\n",
    "model_specs =  f\"Learning Rate: {best_gb_3.learning_rate}, Tree Depth: {best_gb_3.max_depth}, Number of Trees: {best_gb_3.n_estimators}\\n\\nQuadratic Kappa Score: {kappa_3:.4f}\"   \n",
    "upper_ax = fig.add_subplot(grid_spec[0, :])\n",
    "\n",
    "# plt.upper_ax_adjust(hspace = 0.5)\n",
    "upper_text = upper_ax.text(0.5, 0.55, model_specs, ha='center', fontsize=12,\n",
    "                           bbox=dict(facecolor='lightgray', alpha=0.5, boxstyle='round,pad=0.5'))\n",
    "upper_ax.axis('off')\n",
    "\n",
    "# Confusion Matrix Subplot\n",
    "conf_matrix_display = ConfusionMatrixDisplay.from_predictions(y_val, y_pred_3, ax=fig.add_subplot(grid_spec[1, 0]))\n",
    "conf_matrix_display.ax_.set_title(\"Confusion Matrix\")\n",
    "\n",
    "# Normalized Confusion Matrix Subplot\n",
    "normalized_conf_matrix_display = ConfusionMatrixDisplay.from_predictions(y_val, y_pred_3,\n",
    "                                                                         normalize='true',\n",
    "                                                                         values_format='.0%',\n",
    "                                                                         ax=fig.add_subplot(grid_spec[1, 1]))\n",
    "normalized_conf_matrix_display.ax_.set_title(\"Normalized Confusion Matrix\")\n",
    "\n",
    "\n",
    "# Adjust Layout\n",
    "plt.tight_layout\n",
    "plt.suptitle(\"Confusion Matrix from Third Search Round Gradient Boosted Search\", fontsize=20)\n",
    "\n",
    "# Save and show the figure\n",
    "output_filename = f\"{gb_output_path}/gb_3rd_model_kappa={kappa_3:.4f}_confusion_matrix.png\"\n",
    "plt.savefig(output_filename)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
